# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['explode_types', 'explode_lens', 'explode_shapes', 'explode_ranges', 'ImageNTuple', 'ImageTupleBlock',
           'ConditionalGenerator', 'SiameseCritic', 'GenMetric', 'CriticMetric', 'l1', 'l1',
           'download_file_from_google_drive', 'save_response_content', 'FID_WEIGHTS_URL']

# Cell
import requests
from fastcore.all import *
from fastai.data.all import *
from fastai.vision.core import *
from fastai.vision.data import *
from fastai.basics import *
from fastai.vision.gan import *
from fastai.vision.models.all import *
from fastai.vision.augment import *

# Cell
def explode_types(o):
    '''Like fastcore explode_types, but only shows __name__ of type.'''
    if not is_listy(o): return type(o).__name__
    return {type(o).__name__: [explode_types(o_) for o_ in o]}

# Cell
def explode_lens(o):
    if is_listy(o):
        if all(is_listy(o_) for o_ in o):
            return [explode_lens(o_) for o_ in o]
        else: return len(o)

# Cell
def explode_shapes(o):
    if not is_listy(o): return tuple(bind(getattr, arg0, 'shape')(o))
    return [explode_shapes(o_) for o_ in o]

# Cell
def explode_ranges(o):
    if not is_listy(o): return (float(o.min()), float(o.max()))
    return [explode_ranges(o_) for o_ in o]

# Cell
class ImageNTuple(fastuple):
    @classmethod
    def create(cls, fns): return cls(tuple(PILImage.create(f) for f in fns))

    def show(self, ctx=None, **kwargs):
        all_tensors = all([isinstance(t, Tensor) for t in self])
        same_shape = all([self[0].shape==t.shape for t in self[1:]])
        if not all_tensors or not same_shape: return ctx
        line = self[0].new_zeros(self[0].shape[0], self[0].shape[1], 10)
        imgs = sum(L(zip(self, [line]*len(self))).map(list),[])
        return show_image(torch.cat(imgs, dim=2), ctx=ctx, **kwargs)

    def requires_grad_(self, value):
        for item in self: item.requires_grad_(value)
        return self

# Cell
def ImageTupleBlock():
    '''Like fastai tutoria siemese transform, but uses ImageNTuple.'''
    return TransformBlock(type_tfms=ImageNTuple.create, batch_tfms=[IntToFloatTensor])

# Cell
class ConditionalGenerator(nn.Module):
    '''Wraper around a GAN generator that returns the generated image and the input.'''
    @delegates(DynamicUnet)
    def __init__(self, encoder, n_classes, img_size, **kwargs):
        super().__init__()
        self.gen = DynamicUnet(encoder, n_classes, img_size, **kwargs)
    def forward(self, x):
        if is_listy(x):
            input = torch.cat(x, axis=1)
        else:
            input = x
        return ImageNTuple(x, TensorImage(self.gen(input)))

# Cell
class SiameseCritic(Module):
    def __init__(self, critic): self.critic = critic
    def forward(self, x): return self.critic(torch.cat(x, dim=1))

# Cell
class GenMetric(AvgMetric):
    def accumulate(self, learn):
        if learn.model.gen_mode:
            super().accumulate(learn)

# Cell
class CriticMetric(AvgMetric):
    def accumulate(self, learn):
        if not learn.model.gen_mode:
            super().accumulate(learn)

# Cell
def l1(output, target): return nn.L1Loss()(output[-1], target[-1])
l1 = GenMetric(l1)

# Cell
@typedispatch
def show_results(x:TensorImage, y:ImageNTuple, samples, outs, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):
    max_n = min(x.shape[0], max_n)
    if max_n<ncols: ncols = max_n
    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)
    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)
    for i,ctx in enumerate(ctxs):
        title = 'Input-Real-Fake'
        ImageNTuple(x[i], y[1][i], outs[i][0][1]).show(ctx=ctx, title=title)

# Cell
@patch
def show_results(self:GANLearner, ds_idx=1, dl=None, max_n=9, shuffle=True, **kwargs):
    if dl is None: dl = self.dls[ds_idx].new(shuffle=shuffle)
    b = dl.one_batch()
    _,_,preds = self.get_preds(dl=[b], with_decoded=True)
    preds = (preds,)
    self.dls.show_results(b, preds, max_n=max_n, **kwargs)

# Cell
URLs.FACADES = 'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz'
URLs.FACADES_BASE = 'http://cmp.felk.cvut.cz/~tylecr1/facade/CMP_facade_DB_base.zip'
URLs.FACADES_EXTENDED = 'http://cmp.felk.cvut.cz/~tylecr1/facade/CMP_facade_DB_extended.zip'
URLs.CELEBA = '0B7EVK8r0v71pZjFTYXZWM3FlRnM'

# Cell
def download_file_from_google_drive(file_id, destination, folder_name=None):
    if folder_name:
        dst = Config()['data'] / folder_name
        if dst.exists():
            return dst
    else:
        dst = Config()['data']
    arch_dst = Config()['archive'] / destination
    if not arch_dst.exists():
        URL = "https://docs.google.com/uc?export=download"
        session = requests.Session()
        response = session.get(URL, params = { 'id' : file_id }, stream = True)
        token = first([(k,v) for k,v in response.cookies.items() if k.startswith('download_warning')])[1]
        if token:
            params = { 'id' : file_id, 'confirm' : token }
            response = session.get(URL, params = params, stream = True)
        save_response_content(response, Config()['archive'] / destination)
    file_extract(Config()['archive'] / destination, Config()['data'])
    return dst

def save_response_content(response, destination):
    CHUNK_SIZE = 32768

    with open(destination, "wb") as f:
        for chunk in response.iter_content(CHUNK_SIZE):
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)

# Cell
FID_WEIGHTS_URL = 'https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth'