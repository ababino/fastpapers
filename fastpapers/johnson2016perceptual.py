# AUTOGENERATED! DO NOT EDIT! File to edit: 03_johnson2016perceptual.ipynb (unless otherwise specified).

__all__ = ['vgg16', 'vgg16name2key', 'PerceptualLoss', 'JohnsonResBlock', 'ResnetGenerator', 'ResImageBlock']

# Cell
from itertools import *
import requests
from scipy import linalg
import torch
from torchvision.models.utils import load_state_dict_from_url
from fastprogress.fastprogress import master_bar, progress_bar
from fastai.data.external import untar_data
from fastai.data.transforms import get_image_files
from fastai.data import *
from fastai.basics import *
from fastai.vision.data import *
from fastai.vision.core import *
from fastcore.all import *
from fastai.vision.augment import *
from fastai.vision.gan import *
from fastai.callback.hook import *
from fastai.callback.progress import *
from .core import *
import torch.nn.functional as F

# Cell
vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True).features
c, i, j =0, 0, 1
vgg16name2key = {}
for k, l in vgg16._modules.items():
    if isinstance(l, nn.MaxPool2d): j, i, c = j + 1, 0, 0
    if isinstance(l, nn.ReLU):
        i+=1
        vgg16name2key[f'relu{j}_{i}'] = k

# Cell
class PerceptualLoss(nn.Module):
    def __init__(self, style_target=None, style_weight=1, feature_weight=1, renormalize=True,
                 feature_layer='relu2_2', style_layers_names=['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'],
                 bs=1):
        super().__init__()
        store_attr()
        self.vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True).features.eval()
        self.vgg16 = self.vgg16.requires_grad_(False)
        self.feature_layer = self.vgg16._modules[vgg16name2key[feature_layer]]
        self.renorm = Normalize.from_stats(*renorm_stats, cuda=False) if renormalize else noop
        self.compute_style = not style_target is None
        if self.compute_style:
            self.setup_style()

    def cuda(self, *args, **kwargs):
        self.renorm = Normalize.from_stats(*renorm_stats, cuda=True) if self.renormalize else noop
        if self.compute_style:
            self.Gts = [G.cuda(*args, **kwargs) for G in self.Gts]
        return super().cuda(*args, **kwargs)

    def setup_style(self):
        self.style_layers = L(self.style_layers_names).map(vgg16name2key).map(self.vgg16._modules)
        self.style_target = nn.Parameter(self.style_target, requires_grad=False)
        with Hooks(self.style_layers, lambda m,i,o: o, detach=False) as h:
            y = self.vgg16(self.style_target)
            self.Gts = []
            for phi in h.stored:
                phi = phi.view(phi.shape[0], phi.shape[1], -1)
                G = torch.bmm(phi, phi.transpose(1,2))
                Gr = (G/(phi.shape[1]*phi.shape[2])).repeat(self.bs, 1, 1)
                self.Gts.append(nn.Parameter(Gr.detach(), requires_grad=False))

    def feature_loss(self, output, target):
        with Hook(self.feature_layer, lambda m,i,o: o, detach=False) as h:
            self.vgg16(output)
            phi_input = h.stored[0]
            self.vgg16(target)
            phi_target = h.stored[0]
        return nn.MSELoss(reduction='mean')(phi_input, phi_target)

    def style_loss(self, output, target):
        with Hooks(self.style_layers, lambda m,i,o: o, detach=False) as h:
            self.vgg16(output)
            self.Gis = []
            for phi in h.stored:
                phi = phi.view(phi.shape[0], phi.shape[1], -1)
                G = torch.bmm(phi, phi.transpose(1,2))
                self.Gis.append(G/(phi.shape[1]*phi.shape[2]))
        return sum([nn.MSELoss(reduction='sum')(Gi, Gt[:Gi.shape[0]]) for Gi, Gt in zip(self.Gis, self.Gts)])/output.shape[0]

    def forward(self, output, target):
        output = self.renorm(output)
        target = self.renorm(target)
        feature_loss = self.feature_loss(output, target)
        style_loss = self.style_loss(output, target) if self.compute_style else tensor(0)
        return feature_loss*self.feature_weight + style_loss*self.style_weight

# Cell
class JohnsonResBlock(nn.Module):
    def __init__(self, n):
        super().__init__()
        self.convpath = nn.Sequential(ConvLayer(n, n, 3, padding_mode='reflect'),
                                       ConvLayer(n, n, 3, padding_mode='reflect', act_cls=None))
    def forward(self, x):
        return self.convpath(x)+x

# Cell
def ResnetGenerator(ni=3, nout=3, nf=32, n_downsamples=2, n_resblocks=5, n_upsamples=2, superres=False):
    layers = [ConvLayer(ni, nf, 9, padding_mode='reflect')]
    for i in range(n_downsamples):
        layers.append(ConvLayer(nf, nf*2, 3, padding_mode='reflect', stride=2))
        nf*=2
    for i in range(n_resblocks):
        layers.append(JohnsonResBlock(nf))
    for i in range(n_upsamples):
        nout = nf if superres else nf//2
        layers.append(ConvLayer(nf, nout, 3, transpose=True, stride=2, output_padding=1, padding=1))
        if not superres: nf//=2
    layers.append(ConvLayer(nf, 3,9, padding_mode='reflect', act_cls=None))
    layers.append(nn.Tanh())
    return nn.Sequential(*layers)

# Cell
def ResImageBlock(res):
    '''Like fastai `ImageBlock`, but changes the resolution to `res`.'''
    return TransformBlock(type_tfms=[PILImage.create, Resize(res, ResizeMethod.Squish)], batch_tfms=IntToFloatTensor)