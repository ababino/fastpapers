# AUTOGENERATED! DO NOT EDIT! File to edit: 03_johnson2016perceptual.ipynb (unless otherwise specified).

__all__ = ['artists_sources', 'vgg16', 'vgg16name2key', 'gramm_matrix', 'anisotropic_total_variation', 'PerceptualLoss',
           'JohnsonResBlock', 'ResnetGenerator', 'LossToDevice', 'style_learner', 'ResImageBlock', 'superres_learner']

# Cell
from itertools import *
import requests
from scipy import linalg
import torch
from torchvision.models.utils import load_state_dict_from_url
import torchvision.models
import torchfile
from fastprogress.fastprogress import master_bar, progress_bar
from fastai.data.external import untar_data
from fastai.data.transforms import get_image_files
from fastai.data import *
from fastai.basics import *
from fastai.vision.all import *
from fastcore.all import *
from fastai.vision.gan import *
from fastai.callback.hook import *
from fastai.callback.progress import *
from .core import *
import torch.nn.functional as F

# Cell
artists_sources = {'picasso': 'https://i.pinimg.com/originals/45/e1/c2/45e1c21835ef2bd9b0f4b1a9a0a6ad98.jpg',
                   'hokusai': 'https://canary.contestimg.wish.com/api/webimage/58db571f2beb150ea4d4be44-large.jpg?cache_buster=6748460fdd0b539b8f6366f7f86cc267',
                   'vangogh': 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/2560px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'}

# Cell
vgg16 = torchvision.models.vgg16(pretrained=False).features
c, i, j =0, 0, 1
vgg16name2key = {}
for k, l in vgg16._modules.items():
    if isinstance(l, nn.MaxPool2d):
        vgg16name2key[f'pool{j}'] = k
        j, i, c = j + 1, 0, 0
    if isinstance(l, nn.ReLU):
        i+=1
        vgg16name2key[f'relu{j}_{i}'] = k
    if isinstance(l, nn.Conv2d):
        c+=1
        vgg16name2key[f'conv{j}_{c}'] = k

# Cell
def gramm_matrix(x):
    bs, c, h, w = x.shape
    x = x.view(bs, c, h*w)
    return x.bmm(x.transpose(1,2)).view(bs, c*c)/(c*h*w)

# Cell
def anisotropic_total_variation(x):
    return  nn.L1Loss(reduction='sum')(x[:,:, 1:,1:],x[:,:,:-1,:-1])/x.shape[0]

# Cell
class PerceptualLoss(nn.Module):
    def __init__(self, style_target=None, style_weight=5, feature_weight=1, renormalize=True,
                 feature_layer='relu2_2', style_layers_names=['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'],
                 bs=1, cuda=True, tv_weight=1e-5):
        super().__init__()
        store_attr()
        device = 'cuda' if cuda else 'cpu'
        features = torchvision.models.vgg16(pretrained=False).features
        features.load_state_dict(lua_state_dict)
        max_feature = max((L(style_layers_names) + feature_layer).map(vgg16name2key).map(int))+1
        self.vgg = nn.Sequential(*list(features.children())[:max_feature]).to(device).eval()
        self.vgg = self.vgg.requires_grad_(False)
        if cuda and not style_target is None:
            self.style_target = self.style_target.to('cuda')
        self.feature_layer = self.vgg._modules[vgg16name2key[feature_layer]]
        self.renorm = Normalize.from_stats(*renorm_stats, cuda=cuda) if renormalize else noop
        self.compute_style = not style_target is None
        if self.compute_style:
            self.setup_style()

    def to(self, *args, **kwargs):
        if self.renormalize:
            self.renorm.mean = self.renorm.mean.to(*args, **kwargs)
            self.renorm.std = self.renorm.std.to(*args, **kwargs)
        if self.compute_style:
            self.Gts = self.Gts.to(*args, **kwargs)
        return super().to(*args, **kwargs)

    def setup_style(self):
        self.style_layers = L(self.style_layers_names).map(vgg16name2key).map(self.vgg._modules)
        self.style_target = nn.Parameter(self.style_target, requires_grad=True)
        with Hooks(self.style_layers, lambda m,i,o: o, detach=False) as h:
            y = self.vgg(self.style_target)
            G =  y.new([])
            for phi in h.stored: G = torch.cat([G, gramm_matrix(phi)], dim=1)
        self.Gts = nn.Parameter(G.repeat(self.bs, 1), requires_grad=False)

    def feature_loss(self, output, target):
        with Hook(self.feature_layer, lambda m,i,o: o, detach=False) as h:
            self.vgg(output)
            phi_input = h.stored[0]
            self.vgg(target)
            phi_target = h.stored[0]
        return nn.MSELoss(reduction='mean')(phi_input, phi_target)

    def style_loss(self, output, target):
        with Hooks(self.style_layers, lambda m,i,o: o, detach=False) as h:
            self.vgg(output)
            G = output.new([])
            for phi in h.stored: G = torch.cat([G, gramm_matrix(phi)], dim=1)
        return nn.MSELoss(reduction='sum')(G, self.Gts[:G.shape[0]])/G.shape[0]

    def forward(self, output, target):
        output = self.renorm(output)
        target = self.renorm(target)
        feature_loss = self.feature_loss(output, target) if self.feature_weight>0 else tensor(0)
        style_loss = self.style_loss(output, target) if self.compute_style else tensor(0)
        tv_loss = anisotropic_total_variation(output) if self.tv_weight>0 else tensor(0)
        return feature_loss*self.feature_weight + style_loss*self.style_weight + self.tv_weight*tv_loss

# Cell
class JohnsonResBlock(nn.Module):
    def __init__(self, n):
        super().__init__()
        self.convpath = nn.Sequential(ConvLayer(n, n, 3, padding_mode='reflect'),
                                       ConvLayer(n, n, 3, padding_mode='reflect', act_cls=None))
    def forward(self, x):
        return self.convpath(x)+x

# Cell
def ResnetGenerator(ni=3, nout=3, nf=32, n_downsamples=2, n_resblocks=5, n_upsamples=2, superres=False):
    layers = [ConvLayer(ni, nf, 9, padding_mode='reflect')]
    for i in range(n_downsamples):
        layers.append(ConvLayer(nf, nf*2, 3, padding_mode='reflect', stride=2))
        nf*=2
    for i in range(n_resblocks):
        layers.append(JohnsonResBlock(nf))
    for i in range(n_upsamples):
        nout = nf if superres else nf//2
        layers.append(ConvLayer(nf, nout, 3, transpose=True, stride=2, output_padding=1, padding=1))
        if not superres: nf//=2
    layers.append(ConvLayer(nf, 3,9, padding_mode='reflect', act_cls=None))
    layers.append(nn.Tanh())
    return nn.Sequential(*layers)

# Cell
class LossToDevice(Callback):
    def before_fit(self):
        if hasattr(self.dls, 'device'): self.loss_func.to(self.dls.device)

# Cell
@delegates(Learner)
def style_learner(dls, style_target=None, cbs=None, plkwargs={}, **kwargs):
    model = ResnetGenerator()
    loss_func = PerceptualLoss(style_target=style_target, bs=dls.bs, **plkwargs)
    cbs = L(cbs) + LossToDevice if cbs else LossToDevice
    return Learner(dls, model, loss_func=loss_func, cbs=cbs, **kwargs)

# Cell
def ResImageBlock(res):
    '''Like fastai `ImageBlock`, but changes the resolution to `res`.'''
    return TransformBlock(type_tfms=[PILImage.create, Resize(res, ResizeMethod.Squish)], batch_tfms=IntToFloatTensor)

# Cell
@delegates(Learner)
def superres_learner(dls, superres_factor=4, cbs=None, **kwargs):
    n_upsamples = math.log2(superres_factor)
    assert n_upsamples-int(n_upsamples)==0, 'superres_factor should be a power of 2'
    model = ResnetGenerator(nf=64, n_downsamples=0, n_resblocks=4, n_upsamples=int(n_upsamples), superres=True)
    loss_func = PerceptualLoss(style_weight=0, tv_weight=0)
    cbs = L(cbs) + LossToDevice if cbs else LossToDevice
    return Learner(dls, model, loss_func=loss_func, cbs=cbs, **kwargs)